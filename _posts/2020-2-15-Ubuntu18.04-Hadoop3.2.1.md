---
layout: post
title: Ubuntu 18.04 搭载 Hadoop 3.2.1
categories: [BigData, Hadoop]
description: Build Hadoop 3.2.1 on Ubuntu 18.04
keywords: build, Hadoop, Ubuntu
---

在本文中详细介绍了如何利用 VMware workstation 创造 Ubuntu 18.04 虚拟机，并利用该三台虚拟机进行 Hadoop3.2.1 工作集群的搭建。



## 一、 在VMware Workstation中安装Linux系统

### 1. 安装工作站

&emsp;&emsp;安装的版本是—— pro 15.5.1，软件包来源于[网上](https://www.nocmd.com/740.html)。

&emsp;&emsp;但还是推荐用官方版本，再去找激活方式，因为我安装的时候遇到了一个麻烦，VMware Tools没办法正常安装和使用，猜测可能是由于安装包的原因。这里现列举一下这个问题和解决方案。

* 遇到“虚拟机>>安装VMware Tools"显示灰色，不能点击的问题：

  &emsp;&emsp;这个工具不能用是很糟糕的，因为这样本地就没办法和虚拟机进行直接的文件传输了，只能通过虚拟机联网来下载文件，而且代码也不能直接复制粘贴。这里参考了[教程](https://www.cnblogs.com/TM0831/p/11788018.html)。

  <img src="/images/posts/Ubuntu18.04-Hadoop3.2.1/VMwareTools_notInUse.png" alt="VMware Tools not in use" style="zoom: 33%;" />

  &emsp;&emsp;虽然 VMware Tools 是灰色的，但是 VMware 的下载包里有一个 linux.iso，我们需要在虚拟机>>设置>>CD/DVD，然后使用ISO映像文件将linux.iso镜像文件挂载进来。

  &emsp;&emsp;然后在虚拟机的右下角有一个"CD/DVD"图标，点击连接，就可以在桌面上看到一个光盘文件“VMware Tools”，将其解压安装（sudo ./vmware-install.pl），这里一直回车就好了。

  &emsp;&emsp;重启虚拟机，就可以发现复制粘贴成功了。

  

### 2. 安装Linux系统

&emsp;&emsp;首先了解一下虚拟机下三种网络模式，可以参考文档《[VMware虚拟机三种联网模式](https://blog.csdn.net/qq_28090573/article/details/78730552)》。

> VMnet0：用于虚拟**桥接网络**下的虚拟交换机，在这种模式下，虚拟出来的操作系统就像是局域网中的一台独立的主机，它可以访问网内任何一台机器。所以需要手动为虚拟系统配置IP地址、子网掩码，而且还要和宿主机器处于同一网段，这样虚拟系统才能和宿主机器进行通信。同时，由于这个虚拟系统是局域网中的一个独立的主机系统，那么就可以手工配置它的TCP/IP配置信息，以实现通过局域网的网关或路由器访问互联网。

> VMnet1：用于虚拟**Host-Only**网络下的虚拟交换机，在Host-Only模式下，虚拟网络是一个全封闭的网络，它唯一能够访问的就是主机。其实Host-Only网络和NAT网络很相似，不同的地方就是Host-Only网络没有NAT服务，所以虚拟网络不能连接到Internet。主机和虚拟机之间的通信是通过VMware Network Adepter VMnet1虚拟网卡来实现的。此时如果想要虚拟机上外网则需要主机联网并且网络共享。

> VMnet8：用于虚拟**NAT网络**下的虚拟交换机，使用NAT模式，就是让虚拟系统借助NAT(网络地址转换)功能，通过宿主机器所在的网络来访问公网，即互联网。NAT模式下的虚拟系统的TCP/IP配置信息是由VMnet8(NAT)虚拟网络的DHCP服务器提供的，无法进行手工修改，因此虚拟系统也就无法和本局域网中的其他真实主机进行通讯。采用NAT模式最大的优势是虚拟系统接入互联网非常简单，不需要进行任何其他的配置，只需要主机器能访问互联网即可。这种情况下，主机可以ping通虚拟机，虚拟机也能ping通主机。

&emsp;&emsp;所以这里我们采用NAT模式，虚拟机可以访问互联网的同时和主机之间也能ping通。所以这里我们采用NAT模式。默认的设置是启动DHCP服务的，NAT会自动给虚拟机分配IP，但是我们需要将各个机器的IP固定下来，所以要取消这个默认设置。然后为机器设置一个子网网段，我们这里设置为254网段，将来各个虚拟机Ip就为 192.168.254.*。点击NAT设置按钮，打开对话框，可以修改网关地址和DNS地址。



&emsp;&emsp;下载Ubuntu系统，这里选用的是[阿里云Ubuntu 18.04源](http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse)，然后再工作站中创建虚拟机，将其镜像文件导入，创建了第一台虚拟机，先打开试试，这里我尝试的时候报了两个错误：

* VM 与 Device/Credential Guard 不兼容

  &emsp;分析原因可能是——

  &emsp;&emsp;①Device Guard或Credential Guard与Workstation不兼容，那么就需要禁用它们：禁用用于启用Credential Guard的组策略设置。 在主机操作系统上，右键单击“开始” >>“运行”>>gpedit.msc。 转至本地计算机策略 >> 计算机配置 >> 管理模板>>系统 >>Device Guard（设备防护） >> 启用基于虚拟化的安全性，选择已禁用。

  &emsp;&emsp;②Windows系统的Hyper-V不兼容导致，需要关闭Hyper-V，这里注意一下有时候控制面板>>卸载程序>>打开或关闭Windows功能>>关闭Hyper-V，重启也不行，得以管理员身份运行Windows Powshell，输入如下命令：```set hypervisorlaunchtype off```

  

* 无法打开虚拟机 获得所有权失败

  &emsp;分析原因可能是——

  &emsp;&emsp;虚拟机的硬盘和自己电脑的主机是共享硬盘的。当虚拟机使用主机时就会产生一个**硬盘锁**。如果正常关机或者关闭虚拟机，会自动将这个锁关掉。遇到非正常情况，则会继续存在在硬盘之中。有了这个文件，打开虚拟机软件的时候，系统就会判断该虚拟机为打开状态，使无法运行。

  &emsp;&emsp;所以我们只要去虚拟机目录下，找到lck文件并且删除就好了。

  

&emsp;&emsp;按照主机克隆出两台虚拟机，这里三台虚拟机设备内存分配均为2GB，磁盘空间为20GB。



### 3. 虚拟机的网络配置

&emsp;①修改主机名，为了方便后续操作。在三台虚拟机上分别进行```$ sudo vim /etc/hostname```将三台主机名分别改为master，slaver1，slaver2。

> **hostname**中存放的是主机名。
>
> **hosts**存放的是域名与ip的对应关系，域名与主机名没有任何关系，可为任何一个IP指定任意一个名字。

&emsp;②为每个虚拟机更新软件源和软件```$ sudo apt-get update```，检查是不是存在更新的软件版本，```$ sudo apt upgrade```更新下载源。这里是为了之后安装软件包方便。

> 在ubuntu下，我们维护一个源列表，源列表里面都是一些网址信息，这每一条网址就是一个源，这个地址指向的数据标识着这台源服务器上有哪些软件可以安装使用。
>
> ```$ sudo gedit /etc/apt/sources.list```
>
> 第一个命令会访问源列表的每个网址，并读取软件列表，然后保存在本地电脑。第二个命令会把本地已安装的软件，与刚下载的软件列表里对应软件进行对比，如果发现已安装的软件版本太低，会提示你更新。如果都已是最新版本，会提示 “升级了 0 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 0 个软件包未被升级”。

&emsp;③查看三台虚拟机的IP地址```$ ifconfig```，并检查是否连通，如```$ ping 192.168.254.129```。

&emsp;④修改主机映射，将域名与ip名对应上，每一台主机都要修改。```$ sodo vim /etc/hosts```。

```powershell
192.168.254.128 master
192.168.254.129 slaver1
192.168.254.130 slaver2
```



### 4. 实现主机之间的免密登录

&emsp;① 给三台虚拟机都安装ssh：```$ sudo apt install ssh```；

&emsp;② 在master机子上使用rsa算法生成密钥和公钥对，放在“~/.ssh/id_rsa.pub"和"id_rsa"内：```$ ssh-keygen -t rsa```；

&emsp;③ 放入三个密钥：

```powershell
ssh-copy-id master #提示输入密码
ssh-copy-id slaver1 #提示输入密码
ssh-copy-id slaver2 #提示输入密码
```

&emsp;④ 将id_rsa.pub（公钥）添加到authorized_keys（存放所有公钥的文件）中，实现无密码访问本机：

```powershell
$ sudo cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys
$ ssh localhost
```

&emsp;⑤ 将公钥复制到slaver1和saver2上（在master上操作），将master_key追加到slaver1和saver2上authorized_keys文件夹下（在slaver上操作）：

```po
$ scp .ssh/id_rsa.pub xiaolongbao@slaver1:~/.ssh/master_key
$ scp .ssh/id_rsa.pub xiaolongbao@slaver2:~/.ssh/master_key
# 上面的命令在master上完成，下面的在slaver1和2上操作
$ cd ~/.ssh/
$ cat master_key >> authorized_keys
```

&emsp;成功之后应该就可以直接```$ sudo ssh slaver1```了。



## 二、 配置JDK和Hadoop

### 1. 安装JDK

&emsp;这里我安装的是默认的JavaOpenJDK，可以参考[教程](https://linuxize.com/post/install-java-on-ubuntu-18-04/)：```$ sudo apt install default-jdk```，很方便的一行代码安装最新版本的JDK，可以用```$ java -version```来确认是否安装成功。

> JRE is included in the JDK package. If you need only JRE, install the `default-jre` package.

* 但是这里有一个问题要解决，就是之后可能会遇到的```JAVA_HOME```等环境变量配置问题，可以看到此时用命令```$ echo $JAVA_HOME```是什么返回值都没有的，所以我们需要自己去寻找java安装位置，参考[教程](https://www.kutu66.com//ubuntu/article_165145)。

  ```powershell
  $ type -p javac
  /usr/bin/javac
  
  $ readlink -f/usr/bin/javac
  /usr/lib/jvm/java-11-openjdk-amd64/bin/javac
  
  $ dirname/usr/lib/jvm/java-8-oracle/bin/javac
  /usr/lib/jvm/java-11-openjdk-amd64/bin/
  
  $ dirname/usr/lib/jvm/java-8-oracle/bin/
  /usr/lib/jvm/java-11-openjdk-amd64/
  
  export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64/
  ```

  

### 2. 安装Hadoop

&emsp;&emsp;安装包自行[下载](https://mirrors.cnnic.cn/apache/hadoop/common/stable/hadoop-3.2.1.tar.gz)。

```powershell
# 把压缩包经过VMwareTools复制粘贴到虚拟机中
# 把hadoop解压到/usr/local/目录下
sudo tar -zxvf hadoop-3.1.2.tar.gz -C /usr/local
# 把hadoop-3.2.1改名为hadoop
Sudo mv hadoop-3.2.1 hadoop
# 安装vim命令
sudo apt-get install vim-gtk
```

&emsp;&emsp;编辑hadoop-env.sh：```export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64/```

&emsp;&emsp;接着配置Hadoop相关文件。按照[教程](https://www.cnblogs.com/noodlesmars/p/11848488.html)分别配置master节点的:

* ```core-site.xml```：配置通用属性，例如HDFS和MapReduce常用的I/O设置等；

* ```hdfs-site.xml```：Hadoop守护进程配置，包括namenode、辅助namenode和datanode等；

* ```mapred-site.xml```：MapReduce守护进程配置；

* ```yarn-site.xml```：资源调度相关配置。

  

> a. 编辑`core-site.xml`文件，修改内容如下：
>
> ```xml
> <configuration>
>     <property>
>         <name>hadoop.tmp.dir</name>
>         <value>file:/usr/local/hadoop/tmp</value>
>         <description>Abase for other temporary directories.</description>
>     </property>
>     <property>
>         <name>fs.defaultFS</name>
>         <value>hdfs://master:9000</value>
>     </property>
> </configuration>
> ```
>
> 参数说明：
>
> - fs.defaultFS：默认文件系统，HDFS的客户端访问HDFS需要此参数
> - hadoop.tmp.dir：指定Hadoop数据存储的临时目录，其它目录会基于此路径, 建议设置到一个足够空间的地方，而不是默认的/tmp下
>
> > 如没有配置`hadoop.tmp.dir`参数，系统使用默认的临时目录：/tmp/hadoo-hadoop。而这个目录在每次重启后都会被删除，必须重新执行format才行，否则会出错。
>
> b. 编辑`hdfs-site.xml`，修改内容如下：
>
> ```xml
> <configuration>
>     <property>
>         <name>dfs.replication</name>
>         <value>3</value>
>     </property>
>     <property>
>         <name>dfs.name.dir</name>
>         <value>/usr/local/hadoop/hdfs/name</value>
>     </property>
>     <property>
>         <name>dfs.data.dir</name>
>         <value>/usr/local/hadoop/hdfs/data</value>
>     </property>
> </configuration>
> ```
>
> 参数说明：
>
> - dfs.replication：数据块副本数
> - dfs.name.dir：指定namenode节点的文件存储目录
> - dfs.data.dir：指定datanode节点的文件存储目录
>
> c. 编辑`mapred-site.xml`，修改内容如下：
>
> ```xml
> <configuration>
>   <property>
>       <name>mapreduce.framework.name</name>
>       <value>yarn</value>
>   </property>
>   <property>
>     <name>mapreduce.application.classpath</name>
>     <value>$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*</value>
>   </property>
> </configuration>
> ```
>
> d. 编辑`yarn-site.xml`，修改内容如下：
>
> ```xml
> <configuration>
> <!-- Site specific YARN configuration properties -->
>     <property>
>         <name>yarn.nodemanager.aux-services</name>
>         <value>mapreduce_shuffle</value>
>     </property>
>     <property>
>             <name>yarn.resourcemanager.hostname</name>
>             <value>master</value>
>     </property>
>     <property>
>         <name>yarn.nodemanager.env-whitelist</name>
>         <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME</value>
>     </property>
> </configuration>
> ```
>
> e. 编辑`workers`, 修改内容如下：
>
> ```xml
> slave1
> slave2
> ```
>
> 配置worker节点



### 3. 添加环境变量

&emsp;&emsp;为三台虚拟机分别修改环境变量，在```$ sudo vim /etc/profile```的末尾（修改```/etc/bashrc```和```.bashrc```也可以）添加JAVA和HADOOP的变量：

```powershell
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:$HOME/bin:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
```

&emsp;&emsp;!!!注意修改完成之后一定要再重新执行```$ source /etc/profile```让其立即生效。

> ```.bashrc```文件在linux系统普通用户目录（cd/home/xxx）或root用户目录（cd/root）下，用指令ls -al可以看到4个隐藏文件。这些文件是每一位用户对终端功能和属性设置，修改.bashrc可以改变环境变量PATH、别名alias和提示符。
>
> 除了可以修改用户目录下的.bashrc文件外，还可以修改如“/etc/profile”文件、“/etc/bashrc”文件及目录“/etc /profile.d”下的文件。但是修改/etc路径下的配置文件将会应用到整个系统，属于**系统级的配置**，而修改用户目录下的.bashrc则只是限制在用户应用上，属于**用户级设置**。两者在应用范围上有所区别。
>
> 作为惯例，所有环境变量名都是大写， Linux是区分大小写的。
>
> 设置一个变量时，直接用名称；假如要获取变量值的话，就要在变量名前加’$’。
>
> 不能用“PATH=/some /directory”，因为这将删除 $PATH 中其他的所有目录，而应该是添加“PATH=$PATH:/some/directory”。
>
> 接着要把定义了的局部变量变为全局变量，使在以后打开的终端中生效，需要将局部变量输出```export PATH=$PATH:/some/directory```。



### 4. 配置好的Hadoop文件分发到子节点

&emsp;&emsp;```$ scp -r /usr/local/hadoop slaver1:/usr/local/```

* ```/usr/local/```文件夹可能因为有权限设置，不能分发成功，可以先换个位置存放，如```$ scp -r /usr/local/hadoop xiaolingbao@slaver1:~```
  然后再去到slaver1转移文件：```$ sudo mv ./hadoop /usr/local/```

  > ###### ubuntu下的mv命令
  >
  > 移动文件
  >
  > mv file1 dir1 # 因为dir1目录是存在的，可以不加 / 直接放入
  >
  > 移动目录
  >
  > mv dir1 dir2 # 因为dir2目录是存在的，可以不加 / 直接放入
  >
  > 目录改名
  >
  > mv dir1 dir3 # 把目录dir1改名为dir3，因为dir3不存在，可以这样执行，如果dir3存在，就会把dir1放入dir3中
  >
  > 文件改名
  >
  > mv file1 file2 # 把文件file1改名为file2，此时原来的file2被file1覆盖



&emsp;&emsp;记得给slaver们也修改环境变量并且执行，然后用```$ hadoop version```命令应该就可以在每台机子上都成功查看hadoop版本了。



## 三. 启动Hadoop

### 1. 格式化HDFS文件系统

&emsp;&emsp;第一次启动时，在master格式化namenode，以后不需要执行。

&emsp;&emsp;进入hadoop/bin文件下，执行```hadoop namenode -format```。

* 报错：Unable to create /usr/local/hadoop/logs. Aborting.

  &emsp;原因是没有在这个文件夹下的写入权限。

  &emsp;```sudo chmod -R 777 /usr/local/hadoop/```

  &emsp;同样每个虚拟机都需要修改权限。

### 2. 启动Hadoop集群

&emsp;&emsp;①进入hadoop/sbin文件夹下，执行```start-all.sh```启动集群，使用jps命令查看运行情况，若无法启动全部节点，可以重新检查相关配置文件。正常启动后，主节点有四个进程，辅节点有三个进程。

<img src="/images/posts/Ubuntu18.04-Hadoop3.2.1/start-all-jps.png"/>

&emsp;&emsp;②查看Hadoop集群状态，```hadoop dfsadmin -report```。结果如下：

```powershell
Configured Capacity: 63004459008 (58.68 GB)
Present Capacity: 32342134784 (30.12 GB)
DFS Remaining: 32342052864 (30.12 GB)
DFS Used: 81920 (80 KB)
DFS Used%: 0.00%
Replicated Blocks:
	Under replicated blocks: 0
	Blocks with corrupt replicas: 0
	Missing blocks: 0
	Missing blocks (with replication factor 1): 0
	Low redundancy blocks with highest priority to recover: 0
	Pending deletion blocks: 0
Erasure Coded Block Groups: 
	Low redundancy block groups: 0
	Block groups with corrupt internal blocks: 0
	Missing block groups: 0
	Low redundancy blocks with highest priority to recover: 0
	Pending deletion blocks: 0

-------------------------------------------------
Live datanodes (3):

Name: 192.168.254.128:9866 (master)
Hostname: master
Decommission Status : Normal
Configured Capacity: 21001486336 (19.56 GB)
DFS Used: 24576 (24 KB)
Non DFS Used: 10244354048 (9.54 GB)
DFS Remaining: 9666695168 (9.00 GB)
DFS Used%: 0.00%
DFS Remaining%: 46.03%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 1
Last contact: Fri Feb 14 09:57:28 PST 2020
Last Block Report: Fri Feb 14 09:47:23 PST 2020
Num of Blocks: 0


Name: 192.168.254.129:9866 (slaver1)
Hostname: slaver1
Decommission Status : Normal
Configured Capacity: 21001486336 (19.56 GB)
DFS Used: 28672 (28 KB)
Non DFS Used: 8105435136 (7.55 GB)
DFS Remaining: 11805609984 (10.99 GB)
DFS Used%: 0.00%
DFS Remaining%: 56.21%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 1
Last contact: Fri Feb 14 09:57:28 PST 2020
Last Block Report: Fri Feb 14 09:47:11 PST 2020
Num of Blocks: 0


Name: 192.168.254.130:9866 (slaver2)
Hostname: slaver2
Decommission Status : Normal
Configured Capacity: 21001486336 (19.56 GB)
DFS Used: 28672 (28 KB)
Non DFS Used: 9041297408 (8.42 GB)
DFS Remaining: 10869747712 (10.12 GB)
DFS Used%: 0.00%
DFS Remaining%: 51.76%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 1
Last contact: Fri Feb 14 09:57:28 PST 2020
Last Block Report: Fri Feb 14 09:47:11 PST 2020
Num of Blocks: 0
```

&emsp;&emsp;web查看集群状态，在浏览器输入 http://192.168.254.128:9870 ，结果如下：

<img src="/images/posts/Ubuntu18.04-Hadoop3.2.1/web_pic.png"/>

参考资料：

1. 《[Hadoop3.2.1版本的环境搭建](https://www.cnblogs.com/noodlesmars/p/11848488.html)》

2. 《[Hadoop集群简介和搭建步骤](https://blog.csdn.net/qq_33880788/article/details/90777236)》

3. 《[【问题记录】VMware Tools是灰色的，不能安装](https://www.cnblogs.com/TM0831/p/11788018.html)》
4. 《[VMware虚拟机三种联网模式](https://blog.csdn.net/qq_28090573/article/details/78730552)》

5. 《[How to Install Java on Ubuntu 18.04](https://linuxize.com/post/install-java-on-ubuntu-18-04/)》
6.  《[[在ubuntu中，如何查找我当前的JAVA_HOME？](https://www.kutu66.com/ubuntu/article_165145)]》