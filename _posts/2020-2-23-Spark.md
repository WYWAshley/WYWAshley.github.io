---
layout: post
title: Spark 基本介绍
categories: [BigData, Spark]
description: description of Spark
keywords: Spark
---

&emsp;&emsp;继 Hadoop 之后，我们继续了解一下现在工业界可能用的更多的 Spark，这篇文章算是我对 Spark 的初印象吧。

&emsp;&emsp;Spark最初由美国加州伯克利大学的AMP实验室于2009年开发，是**基于内存计算**的**大数据并行计算框架**，可用于构建大型的、低延迟的数据分析应用程序。

## 一、Spark相对于Hadoop的优势

&emsp;&emsp;Hadoop虽然已成为大数据技术的事实标准，但其本身还存在诸多缺陷，最主要的缺陷是其MapReduce计算模型延迟过高，无法胜任实时、快速计算的需求，因而只适用于离线批处理的应用场景。

&emsp;&emsp;回顾Hadoop的工作流程，可以发现Hadoop存在如下一些缺点：

* **表达能力有限**。计算都必须要转化成Map和Reduce两个操作，但这并不适合所有的情况，难以描述复杂的数据处理过程；
* **磁盘IO开销大**。每次执行时都需要从磁盘读取数据，并且在计算完成后需要将中间结果写入到磁盘中，IO开销较大；
* **延迟高**。一次计算可能需要分解成一系列按顺序执行的MapReduce任务，任务之间的衔接由于涉及到IO开销，会产生较高延迟。而且，在前一个任务执行完成之前，其他任务无法开始，难以胜任复杂、多阶段的计算任务。
  Spark主要具有如下优点：

&emsp;&emsp;相对的，Spark的计算模式虽然也属于MapReduce，但不局限于Map和Reduce操作，还提供了多种数据集操作类型，编程模型比MapReduce更灵活：

* Spark提供了**内存计算**，中间结果直接放到内存中，带来了更高的迭代运算效率；
* Spark基于**DAG的任务调度执行机制**，要优于MapReduce的迭代执行机制；
* Spark最大的特点就是将计算数据、中间结果都存储在内存中，大大**减少了IO开销**；
* Spark提供了**多种高层次、简洁的API**，通常情况下，对于实现相同功能的应用程序，Spark的代码量要比Hadoop少2-5倍。

>  但Spark并不能完全替代Hadoop，主要用于替代Hadoop中的MapReduce计算模型。实际上，Spark已经很好地融入了Hadoop生态圈，并成为其中的重要一员，它可以借助于YARN实现资源调度管理，借助于HDFS实现分布式存储。

<br/>

## 二、Spark 基本框架

### 1. 在具体讲解 Spark 运行架构之前，需要先了解几个重要的概念：

* RDD（Resilient Distributed Dataset）：弹性分布式数据集，是分布式内存的一个抽象概念，提供了一种高度受限的共享内存模型，详细看此篇[博客](https://github.com/WYWAshley/WYWAshley.github.io.git/2020/02/19/RDD/)；

* DAG（Directed Acyclic Graph）：有向无环图，反映 RDD 之间的依赖关系，详细看此篇[博客](https://blog.csdn.net/u011564172/article/details/70172060)；

  <img src="/images/posts/Spark/DAG-Scheduler.png" alt="DAGScheduler"/>

* Executor：是运行在工作节点（Worker Node）上的一个进程，负责运行任务，并为应用程序存储数据；

* 应用（application）：用户编写的 Spark 应用程序；

* 任务（Task）：运行在 Executor 上的工作单元；

* 作业（Job）：一个作业包含多个 RDD 及作用于相应 RDD 上的各种操作；

* 阶段（Stage）：是作业的基本调度单位，一个作业会分为多组任务，每组任务被称为“阶段”，或者也被称为“任务集”。

<br/>

### 2. Spark 运行基本流程

<img src="/images/posts/Spark/Spark-workflow.jpg" alt="Spark-workflow"/>

1. 当一个 Spark 应用被提交时，首先需要为这个应用构建起基本的运行环境，即由任务控制节点（Driver）创建一个 SparkContext，由 SparkContext 负责和资源管理器（Cluster Manager）的通信以及进行资源的申请、任务的分配和监控等。SparkContext 会向资源管理器注册并申请运行 Executor 的资源；
2.  资源管理器为 Executor 分配资源，并启动 Executor 进程，Executor 运行情况将随着“心跳”发送到资源管理器上；
3.  SparkContext 根据 RDD 的依赖关系构建 DAG 图，DAG 图提交给 DAG 调度器（DAGScheduler）进行解析，将 DAG 图分解成多个“阶段”（每个阶段都是一个任务集），并且计算出各个阶段之间的依赖关系，然后把一个个“任务集”提交给底层的任务调度器（TaskScheduler）进行处理；Executor向 SparkContext 申请任务，任务调度器将任务分发给 Executor 运行，同时，SparkContext 将应用程序代码发放给 Executor；
4.  任务在 Executor 上运行，把执行结果反馈给任务调度器，然后反馈给 DAG 调度器，运行完毕后写入数据并释放所有资源。

<br/>

* Spark运行架构具有以下特点：

1. 每个应用都有自己专属的Executor进程，并且该进程在应用运行期间一直驻留。Executor进程以多线程的方式运行任务，减少了多进程任务频繁的启动开销，使得任务执行变得非常高效和可靠；
   Spark运行过程与资源管理器无关，只要能够获取Executor进程并保持通信即可；
2. **Executor上有一个BlockManager存储模块**，类似于键值存储系统（把内存和磁盘共同作为存储设备），在处理迭代计算任务时，不需要把中间结果写入到HDFS等文件系统，而是直接放在这个存储系统上，后续有需要时就可以直接读取；在交互式查询场景下，也可以把表提前缓存到这个存储系统上，提高读写IO性能；
3. 任务采用了**数据本地性**和**推测执行**等优化机制。数据本地性是尽量将计算移到数据所在的节点上进行，即“计算向数据靠拢”，因为移动计算比移动数据所占的网络资源要少得多。而且，Spark采用了延时调度机制，可以在更大的程度上实现执行过程优化。比如，拥有数据的节点当前正被其他的任务占用，那么，在这种情况下是否需要将数据移动到其他的空闲节点呢？答案是不一定。因为，如果经过预测发现当前节点结束当前任务的时间要比移动数据的时间还要少，那么，调度就会等待，直到当前节点可用。
   <br/>

### 三、Spark 三种部署方式

&emsp;&emsp;Spark应用程序在集群上部署运行时，可以由不同的组件为其提供资源管理调度服务（资源包括CPU、内存等）。比如，可以使用自带的独立集群管理器（standalone），或者使用YARN，也可以使用Mesos。因此，Spark包括三种不同类型的集群部署方式，包括standalone、Spark on Mesos和Spark on YARN。

1. standalone模式
   与MapReduce1.0框架类似，Spark框架本身也自带了完整的资源调度管理服务，可以独立部署到一个集群中，而不需要依赖其他系统来为其提供资源管理调度服务。在架构的设计上，Spark与MapReduce1.0完全一致，都是由一个Master和若干个Slave构成，并且以槽（slot）作为资源分配单位。不同的是，Spark中的槽不再像MapReduce1.0那样分为Map 槽和Reduce槽，而是只设计了统一的一种槽提供给各种任务来使用。
2. Spark on Mesos模式
   Mesos是一种资源调度管理框架，可以为运行在它上面的Spark提供服务。Spark on Mesos模式中，Spark程序所需要的各种资源，都由Mesos负责调度。由于Mesos和Spark存在一定的血缘关系，因此，Spark这个框架在进行设计开发的时候，就充分考虑到了对Mesos的充分支持，因此，相对而言，Spark运行在Mesos上，要比运行在YARN上更加灵活、自然。目前，Spark官方推荐采用这种模式，所以，许多公司在实际应用中也采用该模式。
3. Spark on YARN模式
Spark可运行于YARN之上，与Hadoop进行统一部署，即“Spark on YARN”，其架构如图9-13所示，资源管理和调度依赖YARN，分布式存储则依赖HDFS。

<br/>

## 四、Spark 生态圈

<img src="/images/posts/Spark/Spark-ecosystem.png" alt="Spark-Ecosystem"/>